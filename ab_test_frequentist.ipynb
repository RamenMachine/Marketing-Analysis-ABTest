{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Marketing A/B Test - Frequentist Statistical Analysis\n",
        "\n",
        "**Author**: Analytics Team  \n",
        "**Date**: November 2025  \n",
        "**Version**: 1.0\n",
        "\n",
        "---\n",
        "\n",
        "## Executive Summary\n",
        "\n",
        "This notebook performs comprehensive frequentist statistical testing to determine if the advertising campaign had a statistically significant impact on conversion rates. We employ multiple statistical methods to ensure robust conclusions.\n",
        "\n",
        "## Statistical Methods\n",
        "\n",
        "1. **Two-Sample T-Test (Welch's)**: Tests for difference in means between two groups with unequal variances\n",
        "2. **Chi-Square Test for Independence**: Tests whether group assignment and conversion are independent\n",
        "3. **Bootstrap Confidence Intervals**: Non-parametric confidence interval estimation using resampling\n",
        "4. **Effect Size (Cohen's h/d)**: Measures the magnitude of the difference, independent of sample size\n",
        "5. **Statistical Power Analysis**: Assesses the probability of detecting a true effect\n",
        "\n",
        "## Interpretation Guidelines\n",
        "\n",
        "- **p < 0.05**: Statistically significant difference\n",
        "- **0.05 ≤ p < 0.10**: Marginally significant (proceed with caution)\n",
        "- **p ≥ 0.10**: No significant difference detected\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from scipy.stats import chi2_contingency\n",
        "from statsmodels.stats.power import TTestIndPower\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Preparation\n",
        "\n",
        "Load the data and separate into test (ad) and control (psa) groups.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load data\n",
        "df = pd.read_csv('marketing_AB.csv')\n",
        "\n",
        "# Separate groups\n",
        "ad_group = df[df['test group'] == 'ad']\n",
        "psa_group = df[df['test group'] == 'psa']\n",
        "\n",
        "# Extract conversion data\n",
        "ad_conversions = ad_group['converted'].values\n",
        "psa_conversions = psa_group['converted'].values\n",
        "\n",
        "# Calculate conversion rates\n",
        "cr_ad = ad_conversions.mean()\n",
        "cr_psa = psa_conversions.mean()\n",
        "n_ad = len(ad_conversions)\n",
        "n_psa = len(psa_conversions)\n",
        "\n",
        "print(f\"Ad Group:  {n_ad:,} users, Conversion Rate: {cr_ad:.6f} ({cr_ad*100:.4f}%)\")\n",
        "print(f\"PSA Group: {n_psa:,} users, Conversion Rate: {cr_psa:.6f} ({cr_psa*100:.4f}%)\")\n",
        "print(f\"Difference: {cr_ad - cr_psa:.6f} ({(cr_ad - cr_psa)*100:.4f}%)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Two-Sample T-Test\n",
        "\n",
        "### Hypothesis Testing\n",
        "\n",
        "**Null Hypothesis ($H_0$)**: There is no difference in conversion rates between ad and psa groups\n",
        "$$H_0: \\mu_{\\text{ad}} = \\mu_{\\text{psa}}$$\n",
        "\n",
        "**Alternative Hypothesis ($H_1$)**: There is a difference in conversion rates\n",
        "$$H_1: \\mu_{\\text{ad}} \\neq \\mu_{\\text{psa}}$$\n",
        "\n",
        "### T-Statistic Formula\n",
        "\n",
        "For unequal variances (Welch's t-test):\n",
        "\n",
        "$$t = \\frac{\\bar{x}_1 - \\bar{x}_2}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}}$$\n",
        "\n",
        "where:\n",
        "- $\\bar{x}_1, \\bar{x}_2$ are sample means\n",
        "- $s_1^2, s_2^2$ are sample variances\n",
        "- $n_1, n_2$ are sample sizes\n",
        "\n",
        "### Degrees of Freedom (Welch's Approximation)\n",
        "\n",
        "$$df = \\frac{\\left(\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}\\right)^2}{\\frac{(s_1^2/n_1)^2}{n_1-1} + \\frac{(s_2^2/n_2)^2}{n_2-1}}$$\n",
        "\n",
        "### Confidence Interval\n",
        "\n",
        "For a $(1-\\alpha)$ confidence interval:\n",
        "\n",
        "$$CI = (\\bar{x}_1 - \\bar{x}_2) \\pm t_{\\alpha/2, df} \\times SE$$\n",
        "\n",
        "where $SE = \\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization: T-Test Results\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Distribution comparison\n",
        "axes[0].hist(ad_conversions, bins=2, alpha=0.7, label='Ad Group', color='#3B82F6', edgecolor='black', linewidth=1.5)\n",
        "axes[0].hist(psa_conversions, bins=2, alpha=0.7, label='PSA Group', color='#6B7280', edgecolor='black', linewidth=1.5)\n",
        "axes[0].axvline(cr_ad, color='#3B82F6', linestyle='--', linewidth=2, label=f'Ad Mean: {cr_ad:.4f}')\n",
        "axes[0].axvline(cr_psa, color='#6B7280', linestyle='--', linewidth=2, label=f'PSA Mean: {cr_psa:.4f}')\n",
        "axes[0].set_xlabel('Conversion (0=No, 1=Yes)', fontsize=12, fontweight='bold')\n",
        "axes[0].set_ylabel('Frequency', fontsize=12, fontweight='bold')\n",
        "axes[0].set_title('Conversion Distribution Comparison', fontsize=14, fontweight='bold', pad=20)\n",
        "axes[0].legend(fontsize=11)\n",
        "axes[0].grid(alpha=0.3, linestyle='--')\n",
        "\n",
        "# Confidence interval visualization\n",
        "ci_range = ci_95_upper - ci_95_lower\n",
        "axes[1].errorbar(0, cr_ad - cr_psa, yerr=[[cr_ad - cr_psa - ci_95_lower], [ci_95_upper - (cr_ad - cr_psa)]], \n",
        "                 fmt='o', markersize=12, capsize=10, capthick=2, color='green' if p_value < 0.05 else 'red',\n",
        "                 label=f'Difference: {cr_ad - cr_psa:.6f}')\n",
        "axes[1].axhline(y=0, color='black', linestyle='--', linewidth=1.5)\n",
        "axes[1].set_xlim(-0.5, 0.5)\n",
        "axes[1].set_ylabel('Difference in Conversion Rate', fontsize=12, fontweight='bold')\n",
        "axes[1].set_title('95% Confidence Interval for Difference', fontsize=14, fontweight='bold', pad=20)\n",
        "axes[1].set_xticks([])\n",
        "axes[1].legend(fontsize=11)\n",
        "axes[1].grid(alpha=0.3, linestyle='--')\n",
        "axes[1].text(0, ci_95_upper + 0.0001, f'Upper: {ci_95_upper:.6f}', ha='center', fontsize=10)\n",
        "axes[1].text(0, ci_95_lower - 0.0001, f'Lower: {ci_95_lower:.6f}', ha='center', fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Perform t-test (unequal variances - Welch's t-test)\n",
        "t_stat, p_value = stats.ttest_ind(ad_conversions, psa_conversions, equal_var=False)\n",
        "\n",
        "# Calculate standard errors\n",
        "se_ad = np.std(ad_conversions, ddof=1) / np.sqrt(n_ad)\n",
        "se_psa = np.std(psa_conversions, ddof=1) / np.sqrt(n_psa)\n",
        "se_diff = np.sqrt(se_ad**2 + se_psa**2)\n",
        "\n",
        "# Degrees of freedom (Welch's approximation)\n",
        "var_ad = np.var(ad_conversions, ddof=1)\n",
        "var_psa = np.var(psa_conversions, ddof=1)\n",
        "df_welch = (se_ad**2 + se_psa**2)**2 / (se_ad**4/(n_ad-1) + se_psa**4/(n_psa-1))\n",
        "\n",
        "# 95% Confidence interval\n",
        "ci_95_lower = (cr_ad - cr_psa) - stats.t.ppf(0.975, df_welch) * se_diff\n",
        "ci_95_upper = (cr_ad - cr_psa) + stats.t.ppf(0.975, df_welch) * se_diff\n",
        "\n",
        "print(\"T-TEST RESULTS\")\n",
        "print(\"=\"*60)\n",
        "print(f\"T-statistic: {t_stat:.6f}\")\n",
        "print(f\"P-value: {p_value:.6f}\")\n",
        "print(f\"Degrees of Freedom (Welch): {df_welch:.2f}\")\n",
        "print(f\"95% CI for difference: [{ci_95_lower:.6f}, {ci_95_upper:.6f}]\")\n",
        "print(f\"95% CI for difference (%): [{(ci_95_lower*100):.4f}%, {(ci_95_upper*100):.4f}%]\")\n",
        "\n",
        "# Interpretation\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(f\"\\n✅ Statistically Significant (p < {alpha})\")\n",
        "    print(\"   We reject the null hypothesis. There is evidence of a difference.\")\n",
        "else:\n",
        "    print(f\"\\n⚠️  Not Statistically Significant (p ≥ {alpha})\")\n",
        "    print(\"   We fail to reject the null hypothesis.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Chi-Square Test for Independence\n",
        "\n",
        "Tests whether group assignment and conversion are independent.\n",
        "\n",
        "### Chi-Square Statistic\n",
        "\n",
        "$$\\chi^2 = \\sum \\frac{(O_{ij} - E_{ij})^2}{E_{ij}}$$\n",
        "\n",
        "where:\n",
        "- $O_{ij}$ = Observed frequency in cell $(i,j)$\n",
        "- $E_{ij}$ = Expected frequency in cell $(i,j)$\n",
        "\n",
        "### Expected Frequencies\n",
        "\n",
        "$$E_{ij} = \\frac{(\\text{Row Total}_i) \\times (\\text{Column Total}_j)}{\\text{Grand Total}}$$\n",
        "\n",
        "### Degrees of Freedom\n",
        "\n",
        "$$df = (r-1) \\times (c-1)$$\n",
        "\n",
        "where $r$ = number of rows, $c$ = number of columns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create contingency table\n",
        "contingency_table = pd.crosstab(df['test group'], df['converted'])\n",
        "print(\"CONTINGENCY TABLE:\")\n",
        "print(contingency_table)\n",
        "\n",
        "# Perform chi-square test\n",
        "chi2, p_chi2, dof, expected = chi2_contingency(contingency_table)\n",
        "\n",
        "print(f\"\\nCHI-SQUARE TEST RESULTS\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Chi-square statistic: {chi2:.6f}\")\n",
        "print(f\"P-value: {p_chi2:.6f}\")\n",
        "print(f\"Degrees of Freedom: {dof}\")\n",
        "\n",
        "print(f\"\\nExpected Frequencies:\")\n",
        "print(pd.DataFrame(expected, index=contingency_table.index, columns=contingency_table.columns))\n",
        "\n",
        "# Interpretation\n",
        "if p_chi2 < 0.05:\n",
        "    print(f\"\\n✅ Groups are NOT independent (significant association)\")\n",
        "    print(\"   Group assignment and conversion are related.\")\n",
        "else:\n",
        "    print(f\"\\n⚠️  Groups appear independent (no significant association)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Effect Size Calculation\n",
        "\n",
        "Effect size measures the magnitude of the difference, independent of sample size.\n",
        "\n",
        "### Cohen's h (for Proportions)\n",
        "\n",
        "Cohen's h uses the arcsine transformation:\n",
        "\n",
        "$$h = 2 \\times (\\arcsin(\\sqrt{p_1}) - \\arcsin(\\sqrt{p_2}))$$\n",
        "\n",
        "### Cohen's d (for Continuous Variables)\n",
        "\n",
        "$$d = \\frac{\\mu_1 - \\mu_2}{\\sigma_{\\text{pooled}}}$$\n",
        "\n",
        "where the pooled standard deviation is:\n",
        "\n",
        "$$\\sigma_{\\text{pooled}} = \\sqrt{\\frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1 + n_2 - 2}}$$\n",
        "\n",
        "### Interpretation\n",
        "\n",
        "- $|h| < 0.2$: Negligible effect\n",
        "- $0.2 \\leq |h| < 0.5$: Small effect\n",
        "- $0.5 \\leq |h| < 0.8$: Medium effect\n",
        "- $|h| \\geq 0.8$: Large effect\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cohen's h for proportions (arcsine transformation)\n",
        "def cohens_h(p1, p2):\n",
        "    \"\"\"Calculate Cohen's h for two proportions\"\"\"\n",
        "    h = 2 * (np.arcsin(np.sqrt(p1)) - np.arcsin(np.sqrt(p2)))\n",
        "    return h\n",
        "\n",
        "# Cohen's d (for continuous, using conversion rates as means)\n",
        "pooled_std = np.sqrt(((n_ad - 1) * var_ad + (n_psa - 1) * var_psa) / (n_ad + n_psa - 2))\n",
        "cohens_d = (cr_ad - cr_psa) / pooled_std if pooled_std > 0 else 0\n",
        "\n",
        "# Cohen's h\n",
        "cohens_h_value = cohens_h(cr_ad, cr_psa)\n",
        "\n",
        "print(\"EFFECT SIZE METRICS\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Cohen's h: {cohens_h_value:.6f}\")\n",
        "print(f\"Cohen's d: {cohens_d:.6f}\")\n",
        "\n",
        "# Interpretation\n",
        "def interpret_effect_size_h(h):\n",
        "    abs_h = abs(h)\n",
        "    if abs_h < 0.2:\n",
        "        return \"Negligible\"\n",
        "    elif abs_h < 0.5:\n",
        "        return \"Small\"\n",
        "    elif abs_h < 0.8:\n",
        "        return \"Medium\"\n",
        "    else:\n",
        "        return \"Large\"\n",
        "\n",
        "effect_interpretation = interpret_effect_size_h(cohens_h_value)\n",
        "print(f\"\\nEffect Size Interpretation: {effect_interpretation} effect (|h| = {abs(cohens_h_value):.4f})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Bootstrap Confidence Intervals\n",
        "\n",
        "Bootstrap is a non-parametric method that resamples the data with replacement to estimate the sampling distribution.\n",
        "\n",
        "### Bootstrap Procedure\n",
        "\n",
        "1. Resample $n_1$ observations from group 1 with replacement\n",
        "2. Resample $n_2$ observations from group 2 with replacement\n",
        "3. Calculate the difference in means\n",
        "4. Repeat $B$ times (typically 10,000)\n",
        "5. Use percentiles of the bootstrap distribution for confidence intervals\n",
        "\n",
        "### Bootstrap Confidence Interval\n",
        "\n",
        "For a $(1-\\alpha)$ confidence interval:\n",
        "\n",
        "$$CI = [Q_{\\alpha/2}, Q_{1-\\alpha/2}]$$\n",
        "\n",
        "where $Q_p$ is the $p$-th percentile of the bootstrap distribution.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def bootstrap_ci(data1, data2, n_bootstrap=10000, ci_level=0.95):\n",
        "    \"\"\"Calculate bootstrap confidence interval for difference in means\"\"\"\n",
        "    n1, n2 = len(data1), len(data2)\n",
        "    differences = []\n",
        "    \n",
        "    for _ in range(n_bootstrap):\n",
        "        # Resample with replacement\n",
        "        sample1 = np.random.choice(data1, size=n1, replace=True)\n",
        "        sample2 = np.random.choice(data2, size=n2, replace=True)\n",
        "        # Calculate difference\n",
        "        diff = sample1.mean() - sample2.mean()\n",
        "        differences.append(diff)\n",
        "    \n",
        "    differences = np.array(differences)\n",
        "    alpha = 1 - ci_level\n",
        "    lower = np.percentile(differences, 100 * alpha/2)\n",
        "    upper = np.percentile(differences, 100 * (1 - alpha/2))\n",
        "    \n",
        "    return lower, upper, differences\n",
        "\n",
        "print(\"Running Bootstrap (10,000 iterations)...\")\n",
        "bootstrap_lower, bootstrap_upper, bootstrap_diffs = bootstrap_ci(\n",
        "    ad_conversions, psa_conversions, n_bootstrap=10000, ci_level=0.95\n",
        ")\n",
        "\n",
        "print(f\"\\nBOOTSTRAP RESULTS\")\n",
        "print(\"=\"*60)\n",
        "print(f\"95% CI for difference: [{bootstrap_lower:.6f}, {bootstrap_upper:.6f}]\")\n",
        "print(f\"95% CI for difference (%): [{(bootstrap_lower*100):.4f}%, {(bootstrap_upper*100):.4f}%]\")\n",
        "print(f\"Bootstrap mean difference: {bootstrap_diffs.mean():.6f}\")\n",
        "print(f\"Bootstrap std error: {bootstrap_diffs.std():.6f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Statistical Power Analysis\n",
        "\n",
        "Statistical power is the probability of correctly rejecting a false null hypothesis.\n",
        "\n",
        "### Power Formula\n",
        "\n",
        "For a two-sample t-test:\n",
        "\n",
        "$$\\text{Power} = 1 - \\beta = P(\\text{reject } H_0 | H_1 \\text{ is true})$$\n",
        "\n",
        "Power depends on:\n",
        "- Effect size (Cohen's d)\n",
        "- Sample size ($n$)\n",
        "- Significance level ($\\alpha$)\n",
        "- Type of test (one-tailed vs two-tailed)\n",
        "\n",
        "### Required Sample Size\n",
        "\n",
        "To achieve a desired power $(1-\\beta)$:\n",
        "\n",
        "$$n = \\frac{2(z_{\\alpha/2} + z_{\\beta})^2 \\sigma^2}{(\\mu_1 - \\mu_2)^2}$$\n",
        "\n",
        "where $z_p$ is the $p$-th percentile of the standard normal distribution.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary & Conclusions\n",
        "\n",
        "### Statistical Test Results\n",
        "- **T-Test P-value**: {p_value:.6f}\n",
        "- **Chi-Square P-value**: {p_chi2:.6f}\n",
        "- **Effect Size (Cohen's h)**: {cohens_h_value:.6f} ({effect_interpretation})\n",
        "- **Statistical Power**: {achieved_power:.2%}\n",
        "\n",
        "### Key Findings\n",
        "- {significance_conclusion}\n",
        "- 95% Confidence Interval: [{ci_95_lower:.6f}, {ci_95_upper:.6f}]\n",
        "- Bootstrap 95% CI: [{bootstrap_lower:.6f}, {bootstrap_upper:.6f}]\n",
        "\n",
        "### Recommendations\n",
        "Based on the frequentist analysis, we can {recommendation} the null hypothesis and conclude that {conclusion}.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary and conclusions\n",
        "significance_conclusion = \"Statistically Significant\" if p_value < 0.05 else \"Not Statistically Significant\"\n",
        "recommendation = \"reject\" if p_value < 0.05 else \"fail to reject\"\n",
        "conclusion = \"there is evidence of a difference in conversion rates\" if p_value < 0.05 else \"there is insufficient evidence of a difference\"\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"FREQUENTIST ANALYSIS SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nStatistical Significance: {significance_conclusion}\")\n",
        "print(f\"Effect Size: {effect_interpretation} (|h| = {abs(cohens_h_value):.4f})\")\n",
        "print(f\"Statistical Power: {achieved_power:.2%}\")\n",
        "print(f\"\\nRecommendation: {recommendation.capitalize()} the null hypothesis\")\n",
        "print(f\"Conclusion: {conclusion}\")\n",
        "\n",
        "# Save results\n",
        "summary = {\n",
        "    'ad_group_size': n_ad,\n",
        "    'psa_group_size': n_psa,\n",
        "    'ad_conversion_rate': cr_ad,\n",
        "    'psa_conversion_rate': cr_psa,\n",
        "    'absolute_lift': cr_ad - cr_psa,\n",
        "    'relative_lift': (cr_ad - cr_psa) / cr_psa,\n",
        "    't_statistic': t_stat,\n",
        "    'p_value': p_value,\n",
        "    'chi2_statistic': chi2,\n",
        "    'chi2_p_value': p_chi2,\n",
        "    'cohens_h': cohens_h_value,\n",
        "    'cohens_d': cohens_d,\n",
        "    'ci_95_lower': ci_95_lower,\n",
        "    'ci_95_upper': ci_95_upper,\n",
        "    'bootstrap_ci_lower': bootstrap_lower,\n",
        "    'bootstrap_ci_upper': bootstrap_upper,\n",
        "    'statistical_power': achieved_power,\n",
        "    'required_sample_size': int(np.ceil(required_n)),\n",
        "    'is_significant': p_value < 0.05\n",
        "}\n",
        "\n",
        "import json\n",
        "with open('frequentist_results.json', 'w') as f:\n",
        "    json.dump({k: float(v) if isinstance(v, (np.integer, np.floating)) else v \n",
        "              for k, v in summary.items()}, f, indent=2)\n",
        "\n",
        "print(\"\\n✅ Results saved to 'frequentist_results.json'\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate achieved power\n",
        "power_analysis = TTestIndPower()\n",
        "achieved_power = power_analysis.power(\n",
        "    effect_size=cohens_d,\n",
        "    nobs1=n_ad,\n",
        "    ratio=n_psa/n_ad,\n",
        "    alpha=0.05,\n",
        "    alternative='two-sided'\n",
        ")\n",
        "\n",
        "print(\"POWER ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Observed effect size (Cohen's d): {cohens_d:.6f}\")\n",
        "print(f\"Sample size (Ad): {n_ad:,}\")\n",
        "print(f\"Sample size (PSA): {n_psa:,}\")\n",
        "print(f\"Achieved power: {achieved_power:.4f} ({achieved_power*100:.2f}%)\")\n",
        "\n",
        "# Calculate required sample size for 80% power\n",
        "required_n = power_analysis.solve_power(\n",
        "    effect_size=cohens_d,\n",
        "    power=0.80,\n",
        "    ratio=1.0,\n",
        "    alpha=0.05,\n",
        "    alternative='two-sided'\n",
        ")\n",
        "\n",
        "print(f\"\\nRequired sample size per group (80% power): {int(np.ceil(required_n)):,}\")\n",
        "if n_ad >= required_n:\n",
        "    print(f\"✅ Sample size is adequate\")\n",
        "else:\n",
        "    print(f\"⚠️  Sample size may be insufficient\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
